import os
import subprocess
import torch
import numpy as np
import tkinter as tk
from tkinter import messagebox
from torch import nn
from utils.dataclass import dataset

# Base model
class NNmodel(nn.Module):
    def __init__(self, input_shape, n_layers, neurons):
        super().__init__()
        self.layers = nn.ModuleList()
        self.layers.append(nn.Linear(input_shape, neurons[0], bias=True))
        self.layers.append(nn.ReLU())
        self.layers.append(nn.BatchNorm1d(neurons[0]))
        for i in range(1, n_layers):
            self.layers.append(nn.Linear(neurons[i - 1], neurons[i], bias=True))
            self.layers.append(nn.ReLU())
            self.layers.append(nn.BatchNorm1d(neurons[i]))
        self.output = nn.Linear(neurons[-1], 1)

    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        x = self.output(x)
        return x

def check_and_prepare_model():
    # Step 1: If best model exists, use it
    if os.path.exists("models/best_model.pth"):
        print("Best model found. Ready to go.")
        return "models/best_model.pth", None
    # Step 2: If at least 10 models, run cross-validation to select the best
    model_files = [f for f in os.listdir("models") if f.endswith(".pth")]
    if len(model_files) >= 10:
        print("Best model not found. Running cross-validation script...")
        subprocess.run(["python", "cross_validation.py"], check=True)
        if os.path.exists("models/best_model.pth"):
            print("Best model generated by cross-validation.")
            return "models/best_model.pth", None
        else:
            print("Cross-validation did not produce a best model. Something went wrong.")
            return None, "Error after cross-validation."
    else:
        # Step 3: If not enough models, run hypertuning first
        print("Not enough models. Running hypertuning script...")
        subprocess.run(["python", "hypertune.py"], check=True)
        print("Running cross-validation script after hypertuning...")
        subprocess.run(["python", "cross_validation.py"], check=True)
        if os.path.exists("models/best_model.pth"):
            print("Best model generated after hypertuning + cross-validation.")
            return "models/best_model.pth", None
        else:
            print("No best model after hypertuning and cross-validation.")
            return None, "Error after hypertuning/cross-validation."

def load_model(model_path):
    obj = torch.load(model_path)
    if isinstance(obj, dict) and "state_dict" in obj:
        params = obj.get("params", None)
        if params is not None:
            neurons = params["neurons"]
            input_shape = data.features.shape[1]
        else:
            neurons = [32, 128, 64, 64, 64, 64]
            input_shape = 6
        n_layers = len(neurons)
        model = NNmodel(input_shape, n_layers, neurons)
        model.load_state_dict(obj["state_dict"])
        print(f"Loaded model with params from checkpoint: {params}")
        return model, neurons
    else:
        neurons = [32, 128, 64, 64, 64, 64]
        input_shape = 6
        n_layers = len(neurons)
        model = NNmodel(input_shape, n_layers, neurons)
        model.load_state_dict(obj)
        print("Loaded model with default config.")
        return model, neurons

def create_gui(model, data):
    # Get default values from the last row in the dataset
    last_row = data.data[-1]
    default_values = [
        str(last_row[0]),         # Year
        str(last_row[1]),         # Month
        str(last_row[2]),         # Salmon KG Prices
        str(last_row[3]),         # Temperatures
        str(last_row[4]),         # Minimum Wages
    ]

    def predict():
        try:
            features = [entry.get().strip() for entry in input_fields]
            print("Input values:", features)

            if any(f == "" for f in features):
                messagebox.showerror("Input Error", "You can't leave any fields empty.")
                return

            year = float(features[0])
            month = features[1].lower().strip()
            salmon_kg = float(features[2])
            temperature = float(features[3])
            min_wage = float(features[4])

            year_scaled = data.scaler.transform([[year]]).flatten()[0]
            try:
                month_encoded = data.le_months.transform([month])[0]
            except Exception as e:
                print("Month error:", e)
                messagebox.showerror(
                    "Input Error",
                    f"Month '{features[1]}' is invalid. Use one of: {list(data.le_months.classes_)}"
                )
                return

            quarter = (month_encoded // 3) + 1
            slm_kgp_scaled = data.scaler_kg.transform([[salmon_kg]]).flatten()[0]
            temperature_scaled = data.scaler_temp.transform([[temperature]]).flatten()[0]
            min_wage_scaled = data.scaler_minwages.transform([[min_wage]]).flatten()[0]

            input_features = np.array([
                year_scaled, month_encoded, temperature_scaled, quarter, slm_kgp_scaled, min_wage_scaled
            ], dtype=np.float64)
            print("Transformed input features:", input_features)  # Debug

            input_tensor = torch.tensor(input_features, dtype=torch.float32).unsqueeze(0)

            # THE KEY LINE: set the model to eval mode for inference
            model.eval()

            with torch.no_grad():
                prediction_scaled = model(input_tensor).item()
                prediction = data.target_scaler.inverse_transform([[prediction_scaled]]).flatten()[0]
                result = prediction.item()
            messagebox.showinfo("Prediction Result", f"Predicted Value: {result:.4f}")
        except Exception as e:
            print("Error in predict():", e)
            messagebox.showerror("Input Error", "Please enter valid numerical values.")

    root = tk.Tk()
    root.title("Prediction GUI")
    root.geometry("340x340")

    tk.Label(root, text="Enter Prediction Inputs", font=("Helvetica", 14)).pack(pady=10)

    labels = ["Year", "Month", "Salmon KG Prices", "Temperatures", "Minimum Wages"]
    input_fields = []

    for i, label in enumerate(labels):
        frame = tk.Frame(root)
        frame.pack(pady=5)
        tk.Label(frame, text=f"{label}:", width=18, anchor="w").pack(side=tk.LEFT)
        entry = tk.Entry(frame, width=15)
        entry.pack(side=tk.LEFT)
        entry.insert(0, default_values[i])
        input_fields.append(entry)

    tk.Button(root, text="Predict", command=predict, bg="lightblue", font=("Helvetica", 12)).pack(pady=20)
    root.mainloop()

if __name__ == "__main__":
    # Check if best model exists or needs to be generated
    model_path, error = check_and_prepare_model()
    if error:
        print(f"Error: {error}")
    else:
        data = dataset("data\\fake_dataset.xlsx")
        model, neurons = load_model(model_path)
        create_gui(model, data)